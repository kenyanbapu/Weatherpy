{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from citipy import citipy\n",
    "import requests as req\n",
    "import unidecode\n",
    "import time\n",
    "from math import sqrt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keys\n",
    "from keys import (gkey, wkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build data frame of randomly generated lat and long\n",
    "location_data = pd.DataFrame()\n",
    "location_data['rand_lat'] = [np.random.uniform(-90,90) for x in range(1500)]\n",
    "location_data['rand_lng'] = [np.random.uniform(-180, 180) for x in range(1500)]\n",
    "\n",
    "# add closest city and country column\n",
    "location_data['closest_city'] = \"\"\n",
    "location_data['country'] = \"\"\n",
    "\n",
    "#find and add closest city and country code\n",
    "for index, row in location_data.iterrows():\n",
    "    lat = row['rand_lat']\n",
    "    lng = row['rand_lng']\n",
    "    location_data.set_value(index, 'closest_city', citipy.nearest_city(lat, lng).city_name)\n",
    "    location_data.set_value(index, 'country', citipy.nearest_city(lat, lng).country_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete repeated cities and find unique city count\n",
    "location_data = location_data.drop_duplicates(['closest_city', 'country'])\n",
    "location_data = location_data.dropna()\n",
    "len(location_data['closest_city'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE BELOW VALUE FOR COUNT MATCHING \n",
    "rec_check = len(location_data['closest_city'])  #Difference is because some city names occur in different countries.\n",
    "rec_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview data\n",
    "location_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only city and country\n",
    "# Remove random lats and lngs (no longer needed)\n",
    "location_data = location_data[['closest_city', 'country']]\n",
    "\n",
    "#rename column headers\n",
    "location_data = location_data.rename(columns = {'closest_city': 'city'})\n",
    "location_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in open weather map's country Id json\n",
    "# downloaded from https://openweathermap.org/appid#work per Openweathermaps documentation\n",
    "\n",
    "api_city_data = pd.read_json('city.list.json')\n",
    "\n",
    "for index, row in api_city_data.iterrows():\n",
    "    lower_city = row['name'].lower() #make all city name lowercase\n",
    "    unaccented = unidecode.unidecode(lower_city) # strip accents from city name\n",
    "    lower_country = row['country'].lower() # make all two digit county \n",
    "    api_city_data.set_value(index, 'name', unaccented) # reset the value of name (city) to stripped down version\n",
    "    api_city_data.set_value(index, 'country', lower_country) # reset the value of country to lower case\n",
    "    \n",
    "api_city_data = api_city_data.rename(columns = {'name': 'city'}) # rename for merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left merge with random cities from location_data\n",
    "\n",
    "merged_df = location_data.merge(api_city_data, how = 'left', on = ('city', 'country'))\n",
    "merged_df = merged_df.drop_duplicates(['city', 'country']) #drop duplicates\n",
    "\n",
    "# to verify with number below\n",
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check with above\n",
    "rec_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview merged_df\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data types clean-up\n",
    "merged_df['coord'] = merged_df['coord'].fillna('') #fill na cells with empty string for coordinates\n",
    "merged_df['id'] = merged_df['id'].fillna(0) # fill na with 0 for id in order to change to int64\n",
    "merged_df['id'] = merged_df['id'].astype(dtype = 'int64') # cast id column as type int64 to remove floating .0\n",
    "merged_df['id'].dtype #check type of id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check how many returned valid ids\n",
    "#merged_df['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which countries did not find ids\n",
    "no_id = merged_df[merged_df['id'] == 0]\n",
    "no_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many without ids\n",
    "len(no_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to find lat and lng for cities missing ids from google geocoding api\n",
    "g_url = 'https://maps.googleapis.com/maps/api/geocode/json?address='\n",
    "\n",
    "counter = 0 #for check of all cities\n",
    "for index,row in merged_df.iterrows():\n",
    "    if row['id'] == 0:\n",
    "        city = row['city']\n",
    "        country = row['country']\n",
    "        print('Now retrieving coordinates for city #%s: %s, %s' %(index, city, country))\n",
    "        target_url = '%s%s,+%s&key=%s' % (g_url, city, country, gkey)\n",
    "        print(target_url)\n",
    "        try:\n",
    "            response = req.get(target_url).json()\n",
    "            response_path = response['results'][0]['geometry']['location']\n",
    "            merged_df.set_value(index, 'coord', {'lon': response_path['lng'], 'lat': response_path['lat']})\n",
    "        except:\n",
    "            print('Missing Data for city #%s: %s,%s' %(index, city, country))\n",
    "        counter += 1\n",
    "#     if counter == 10:\n",
    "#             break\n",
    "\n",
    "print(counter) #to check for same number of records as no_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preview merged_df\n",
    "merged_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check with below\n",
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check with above\n",
    "rec_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check to see how many records with no coordinates\n",
    "no_coord = merged_df[merged_df['coord'] == \"\"]\n",
    "no_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# of records without coordinates\n",
    "len(no_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#leave merged_df the same from here on\n",
    "weather_data = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open Weather Maps Api example links for reference\n",
    "# id url example: 'api.openweathermap.org/data/2.5/weather?id=2172797'\n",
    "# coord url example: 'api.openweathermap.org/data/2.5/weather?lat=35&lon=139'\n",
    "# city search use : api.openweathermap.org/data/2.5/weather?q=London,uk\n",
    "# remember to use &appid= for key\n",
    "\n",
    "counter = 0 #for breaking and pausing\n",
    "cur_err_list = [] # for cities without data from current weather\n",
    "for_err_list = [] # for cities without data from forecast data\n",
    "cur_errors = 0  #current weather pull errors\n",
    "for_errors = 0 #forecast weather pull errors\n",
    "\n",
    "#create additional columns for open weather map data\n",
    "\n",
    "#make columnds for lat and lng from open weather source\n",
    "weather_data['lat'] = \"\"\n",
    "weather_data['lng'] = \"\"\n",
    "\n",
    "#make columns for current weather data (at time of pull)\n",
    "weather_data['cur_date'] = \"\"\n",
    "weather_data['cur_temp'] = \"\"\n",
    "weather_data['cur_humidity'] = \"\"\n",
    "weather_data['cur_clouds'] = \"\"\n",
    "weather_data['cur_wind'] = \"\"\n",
    "\n",
    "# make columns for records corresponding to the highest temperature \n",
    "# forecasted in the next 24 hours (from time of pull)\n",
    "weather_data['max_date'] = \"\"\n",
    "weather_data['max_temp'] = \"\"\n",
    "weather_data['max_temp_humidity'] = \"\"\n",
    "weather_data['max_temp_clouds'] = \"\"\n",
    "weather_data['max_temp_wind'] = \"\"\n",
    "\n",
    "# make columns for records corresponding to the average values\n",
    "# forecasted in the next 5 days (from time of pull)\n",
    "weather_data['avg_date0'] = \"\"\n",
    "weather_data['avg_date1'] = \"\"\n",
    "weather_data['avg_temp'] = \"\"\n",
    "weather_data['avg_humidity'] = \"\"\n",
    "weather_data['avg_clouds'] = \"\"\n",
    "weather_data['avg_wind'] = \"\"\n",
    "\n",
    "t0 = time.time() #for pause timer\n",
    "for index, row in weather_data.iterrows():\n",
    "    print('Now retrieving data for city #%s: %s, %s' % (index, row['city'], row['country']))\n",
    "    #uses url believed to be most accurate\n",
    "    if ((row['id']) == 0) and (row['coord'] != \"\"): # coordinates if no id, but with coordinates\n",
    "        lat = row['coord']['lat']\n",
    "        lon = row['coord']['lon']\n",
    "        cur_url = 'https://api.openweathermap.org/data/2.5/weather?lat=%s&lon=%s&APPID=%s&units=imperial' % (lat, lon, wkey)  \n",
    "        for_url = 'https://api.openweathermap.org/data/2.5/forecast?lat=%s&lon=%s&APPID=%s&units=imperial' % (lat, lon, wkey)  \n",
    "    elif row['id'] != 0: # use if if ID exists\n",
    "        loc_id = row['id']\n",
    "        cur_url = 'https://api.openweathermap.org/data/2.5/weather?id=%s&APPID=%s&units=imperial' % (loc_id, wkey)\n",
    "        for_url = 'https://api.openweathermap.org/data/2.5/forecast?id=%s&APPID=%s&units=imperial' % (loc_id, wkey)\n",
    "    else: #use city and country if no id AND no coordinates\n",
    "        city = row['city']\n",
    "        country = row['country']\n",
    "        cur_url = 'https://api.openweathermap.org/data/2.5/weather?q=%s,%s&APPID=%s&units=imperial' % (city, country, wkey)\n",
    "        for_url = 'https://api.openweathermap.org/data/2.5/forecast?q=%s,%s&APPID=%s&units=imperial' % (city, country, wkey)\n",
    "    print('Current Weather URL:')\n",
    "    print(cur_url)\n",
    "    print('Forecast Weather URL:')\n",
    "    print(for_url)\n",
    "    #get current weather data\n",
    "    try:\n",
    "        cur_response = req.get(cur_url).json()\n",
    "        weather_data.set_value(index, 'lat', cur_response['coord']['lat'])\n",
    "        weather_data.set_value(index, 'lng', cur_response['coord']['lon'])\n",
    "        weather_data.set_value(index, 'cur_date', cur_response['dt'])\n",
    "        weather_data.set_value(index, 'cur_temp', cur_response['main']['temp'])\n",
    "        weather_data.set_value(index, 'cur_humidity', cur_response['main']['humidity'])\n",
    "        weather_data.set_value(index, 'cur_clouds', cur_response['clouds']['all'])\n",
    "        weather_data.set_value(index, 'cur_wind', cur_response['wind']['speed'])\n",
    "    except:\n",
    "        print('Missing Current Weather Info for city #%s: %s, %s' % (index, row['city'], row['country']))\n",
    "        cur_err_list.append(index)\n",
    "        cur_errors += 1\n",
    "    try:\n",
    "        #get max temperature weather data\n",
    "        for_response = req.get(for_url).json()\n",
    "        for_path = for_response['list']\n",
    "        temps_24h = [] # a list of temp over a 24 hours period forecased every 3 hours\n",
    "        for n in range(9): # a 24 hour period\n",
    "            temps_24h.append(for_path[n]['main']['temp_max'])\n",
    "        max_index = temps_24h.index(max(temps_24h))\n",
    "        weather_data.set_value(index, 'max_date', for_path[max_index]['dt'])\n",
    "        weather_data.set_value(index, 'max_temp', for_path[max_index]['main']['temp_max'])\n",
    "        weather_data.set_value(index, 'max_temp_humidity', for_path[max_index]['main']['humidity'])\n",
    "        weather_data.set_value(index, 'max_temp_clouds', for_path[max_index]['clouds']['all'])\n",
    "        weather_data.set_value(index, 'max_temp_wind', for_path[max_index]['wind']['speed'])\n",
    "        # get avg forecast values \n",
    "        #set up blank lists for dates, temperature, clouds, wind, humidity over a 5 day period\n",
    "        dat = []\n",
    "        tem = []\n",
    "        clo = []\n",
    "        win = []\n",
    "        hum = []\n",
    "        for n in for_path: # 5 days worth of forecast\n",
    "            dat.append(n['dt'])\n",
    "            tem.append(n['main']['temp'])\n",
    "            clo.append(n['clouds']['all'])\n",
    "            win.append(n['wind']['speed'])\n",
    "            hum.append(n['main']['humidity'])\n",
    "        weather_data.set_value(index, 'avg_date0', dat[0]) #beginning date\n",
    "        weather_data.set_value(index, 'avg_date1', dat[-1]) #ending date\n",
    "        weather_data.set_value(index, 'avg_temp', np.mean(tem)) # mean temp over 5 days\n",
    "        weather_data.set_value(index, 'avg_humidity', np.mean(hum)) #mean humidity over 5 days\n",
    "        weather_data.set_value(index, 'avg_clouds', np.mean(clo)) #mean cloud cover over 5 days\n",
    "        weather_data.set_value(index, 'avg_wind', np.mean(win)) #mean wind speed over 5 days\n",
    "    except:\n",
    "        print('Missing Forecast Info for city #%s: %s, %s' % (index, row['city'], row['country']))\n",
    "        for_err_list.append(index)\n",
    "        for_errors += 1\n",
    "    print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "    counter +=1\n",
    "    if counter % 30 == 0: #because two records pulled for each city \n",
    "        t1 = time.time() #records time very 30 records\n",
    "        sl_time = 70 - (t1-t0) # calculates buffer for api pull limit\n",
    "        print(\"\")\n",
    "        print('********Sleeping for %s seconds.********' % (sl_time))\n",
    "        print(\"\")\n",
    "        time.sleep(sl_time) # pauses for appropraite amount of time\n",
    "        t0 = time.time() # resets for next 30 pull timer\n",
    "#     if counter == 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summary Report\n",
    "print(\"Counts and Errors Report\")\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"Count\")\n",
    "print('----------------')\n",
    "print(str(counter))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"Errors\")\n",
    "print('----------------')\n",
    "print('# of Current Weather Errors: ' + str(cur_errors))\n",
    "print(\"Current Weather Errors Index List:\")\n",
    "\n",
    "if len(cur_err_list) > 0:\n",
    "    for n in cur_errors:\n",
    "        print(n)\n",
    "else:\n",
    "    print('None')\n",
    "print(\"\")\n",
    "print('# of Forecast Weather Errors:' + str(for_errors))\n",
    "print(\"Forecast Weather Errors Index List: \")\n",
    "if len(for_err_list) > 0:\n",
    "    for n in for_errors:\n",
    "        print(n)\n",
    "else:\n",
    "    print('None')\n",
    "print('---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#view columns\n",
    "weather_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean up\n",
    "clean_col = weather_data.columns[4:]\n",
    "clean_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loop throught to clean columns to be able to use for graphs\n",
    "for c in clean_col:\n",
    "    weather_data[c] = pd.to_numeric(weather_data[c], errors = 'coerce') \n",
    "    weather_data = weather_data[weather_data[c].isnull() == False]\n",
    "\n",
    "len(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check weather data types\n",
    "weather_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "weather_data.to_csv('Data_Output/clean_weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## Data CSV read to avoid pull requests again  ########\n",
    "# weather_data = pd.read_csv('Data_Output/clean_weather_data.csv')\n",
    "# weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#date sorting and conversions dictionary for graph labels\n",
    "\n",
    "dates = {'max_cur': weather_data['cur_date'].max(),\n",
    "         'min_cur': weather_data['cur_date'].min(),\n",
    "         'max_max': weather_data['max_date'].max(),\n",
    "         'min_max': weather_data['max_date'].min(),\n",
    "         'min_avg': weather_data['avg_date0'].max(),\n",
    "         'max_avg': weather_data['avg_date1'].min()\n",
    "        }\n",
    "\n",
    "for key in dates.keys():\n",
    "    convert = datetime.utcfromtimestamp(dates[key]).strftime('%Y-%m-%d%, %I:%M:%S %p')\n",
    "    dates[key] = convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary for labels\n",
    "labels_dic = {\"cur_temp\": \"Current Temperature\", \n",
    "              'max_temp': 'Maximum Temp 24 Hours', \n",
    "              'avg_temp': 'Average Forecasted Temp in 5 Days',\n",
    "             'cur_humidity': 'Current Humidity',\n",
    "             'max_temp_humidity': \"Forecasted Humidity (%) at the Maximum Temperature in 24 Hours\",\n",
    "             'avg_humidity': 'Average Forecasted Humidity (%) over 5 Days',\n",
    "             'cur_clouds': 'Current Cloud Cover (%)',\n",
    "             'max_temp_clouds': 'Forecasted Cloud Cover (%) at the Maximum Forecasted Temperature in 24 Hours',\n",
    "             'avg_clouds': 'Average Forecasted Cloud Cover (%) over 5 Days',\n",
    "             'cur_wind': 'Current Wind Speed (mph)',\n",
    "             'max_temp_wind': 'Forecasted Wind Speed (mph) at the Maximum Forecasted Temperature in 24 Hours',\n",
    "             'avg_wind': 'Average Forecasted Wind Speed (mph) over 5 Days'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Temp vs Latitude Graphs\n",
    "temp_list = ['cur_temp', 'max_temp', 'avg_temp']  #would have done only dict but wanted consistent order.\n",
    "\n",
    "xvals = weather_data['lat']\n",
    "\n",
    "for temp in temp_list:\n",
    "    # y values of each item in list for separate graphs\n",
    "    yvals = weather_data[temp]\n",
    "    #adds title including title and timestamp range of sample data\n",
    "    plt.title(\"%s vs Latitude \\n Samples Taken from %s to %s UTC\" % (labels_dic[temp], dates['min_' + temp.split('_')[0]],  dates['max_' + temp.split('_')[0]]))\n",
    "    plt.axvline(0, color = 'black', alpha = .25, label = 'Equator') #adds equator line\n",
    "    plt.text(1,30,'Equator',rotation=90)\n",
    "    plt.ylim(15, 120) #to give consistent scale\n",
    "    plt.xlabel('Latitude')\n",
    "    plt.ylabel(\"Temperature (F)\")\n",
    "    plt.scatter(xvals, yvals)\n",
    "    plt.show()\n",
    "    plt.savefig(\"Graph_Output/%s vs Latitude.png\" % (labels_dic[temp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Humidity vs Latitude Graphs\n",
    "#see first set of graphs commenting for notes\n",
    "hum_list = ['cur_humidity', 'max_temp_humidity', 'avg_humidity']  #would have done only dict but wanted consistent order.\n",
    "\n",
    "xvals = weather_data['lat']\n",
    "\n",
    "for hum in hum_list:\n",
    "    yvals = weather_data[hum]\n",
    "    plt.title(\"%s vs Latitude \\n Samples Taken from %s to %s UTC\" % (labels_dic[hum], dates['min_' + hum.split('_')[0]],  dates['max_' + hum.split('_')[0]]))\n",
    "    plt.xlabel('Latitude')\n",
    "    plt.ylabel('Humidity (%)')\n",
    "    plt.axvline(0, color = 'black', alpha = .25, label = 'Equator')\n",
    "    plt.text(1,20,'Equator',rotation=90)\n",
    "    plt.scatter(xvals, yvals)\n",
    "    plt.show()\n",
    "    plt.savefig(\"Graph_Output/%s vs Latitude.png\" % (labels_dic[hum]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cloud Cover vs Latitude Graphs\n",
    "#see first set of graphs commenting for notes\n",
    "cloud_list = ['cur_clouds', 'max_temp_clouds', 'avg_clouds']  #would have done only dict but wanted consistent order.\n",
    "\n",
    "xvals = weather_data['lat']\n",
    "\n",
    "for clo in cloud_list:\n",
    "    yvals = weather_data[clo]\n",
    "    plt.title(\"%s vs Latitude \\n Samples Taken from %s to %s UTC\" % (labels_dic[clo], dates['min_' + clo.split('_')[0]],  dates['max_' + clo.split('_')[0]]))\n",
    "    plt.xlabel('Latitude')\n",
    "    plt.ylabel('Cloud Cover (%)')\n",
    "    plt.ylim(-5,105)\n",
    "    plt.axvline(0, color = 'black', alpha = .25, label = 'Equator')\n",
    "    plt.text(-5,-20,'Equator')\n",
    "    plt.scatter(xvals, yvals)\n",
    "    plt.show()\n",
    "    plt.savefig(\"Graph_Output/%s vs Latitude.png\" % (labels_dic[clo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wind Speed vs Latitude Graphs\n",
    "#see first set of graphs commenting for notes\n",
    "win_list = ['cur_wind', 'max_temp_wind', 'avg_wind']  #would have done only dict but wanted consistent order.\n",
    "\n",
    "xvals = weather_data['lat']\n",
    "\n",
    "for win in win_list:\n",
    "    yvals = weather_data[win]\n",
    "    plt.title(\"%s vs Latitude \\n Samples Taken from %s to %s UTC\" % (labels_dic[win], dates['min_' + win.split('_')[0]],  dates['max_' + win.split('_')[0]]))\n",
    "    plt.xlabel('Latitude')\n",
    "    plt.ylabel('Wind Speed (mph))')\n",
    "    plt.ylim(-5,60)\n",
    "    plt.axvline(0, color = 'black', alpha = .25, label = 'Equator')\n",
    "    plt.text(1,35,'Equator',rotation=90)\n",
    "    plt.scatter(xvals, yvals)\n",
    "    plt.show()\n",
    "    plt.savefig(\"Graph_Output/%s vs Latitude.png\" % (labels_dic[win]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graphs lats vs long, temperature scale from red(hot) to green(cool), and bubble size based on humidity, cloud cover, and wind speed\n",
    "xvars = weather_data['lng']\n",
    "yvars = weather_data['lat']\n",
    "color = weather_data['avg_temp']\n",
    "size_list = ['avg_humidity', 'avg_clouds', 'avg_wind']\n",
    "\n",
    "#loops through size list and only changes size of bubbles based on different variables\n",
    "for measure in size_list:  \n",
    "    plt.figure(figsize = (18,12))\n",
    "    plt.xlim(-180,180)\n",
    "    plt.ylim(-90,90)\n",
    "    plt.title(\"Global Temperatures Based on 5 Day Average \\n Samples taken from %s to %s UTC \\n Note:  Bubble Size Corresponds to %s\" % (dates['min_avg'], dates['max_avg'], labels_dic[measure]))\n",
    "    plt.axhline(0, color = 'black', alpha = .25, label = 'Equator')\n",
    "    plt.text(-155,3,'Equator')\n",
    "    size = weather_data[measure]\n",
    "    plt.scatter(xvars, \n",
    "                yvars, \n",
    "                c = color, \n",
    "                s = size * 6, \n",
    "                edgecolor = 'black', \n",
    "                linewidth = 1, \n",
    "                alpha = .5, \n",
    "                cmap=plt.cm.RdYlGn_r)\n",
    "    plt.show()\n",
    "    plt.savefig(\"Graph_Output/Global Temperatures Based on 5 Day Average Bubble Plot: %s.png\" % (measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
